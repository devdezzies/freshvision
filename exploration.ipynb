{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch # type: ignore\n",
    "import torchvision # type: ignore\n",
    "from typing import Tuple, Dict, List\n",
    "from pathlib import Path \n",
    "from zipfile import ZipFile\n",
    "from PIL import Image # type: ignore\n",
    "from torch.utils.data import Dataset # type: ignore\n",
    "from torchvision import transforms # type: ignore\n",
    "import os\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data already exist!\n"
     ]
    }
   ],
   "source": [
    "DIR_PATH = Path(\"data\")\n",
    "IMAGE_PATH = DIR_PATH / \"spoiled-fresh\"\n",
    "\n",
    "if IMAGE_PATH.is_dir():\n",
    "    print(\"data already exist!\")\n",
    "else: \n",
    "    print(\"extracting data..\")\n",
    "    with ZipFile(file=DIR_PATH / \"spoiled-fresh.zip\", mode=\"r\") as zip_ref:\n",
    "        zip_ref.extractall(IMAGE_PATH)\n",
    "    os.remove(DIR_PATH / \"spoiled-fresh.zip\")\n",
    "    print(\"[INFO] done unzipping the file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pathlib.WindowsPath"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F_Banana',\n",
       " 'F_Lemon',\n",
       " 'F_Lulo',\n",
       " 'F_Mango',\n",
       " 'F_Orange',\n",
       " 'F_Strawberry',\n",
       " 'F_Tamarillo',\n",
       " 'F_Tomato',\n",
       " 'S_Banana',\n",
       " 'S_Lemon',\n",
       " 'S_Lulo',\n",
       " 'S_Mango',\n",
       " 'S_Orange',\n",
       " 'S_Strawberry',\n",
       " 'S_Tamarillo',\n",
       " 'S_Tomato']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_PATH = DIR_PATH / \"spoiled-fresh\" / \"FRUIT-16K\"\n",
    "sorted(entry.name for entry in os.scandir(IMAGE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom dataset\n",
    "def find_classes(directory: str) -> Tuple[list[str], Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Finds the class folder names in a target directory \n",
    "    \"\"\"\n",
    "    # 1. get the class names by scanning the target directory \n",
    "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "\n",
    "    # 2. raise an error is class names couldn't be found \n",
    "    if not classes:\n",
    "        raise FileNotFoundError(f\"couldn't find any classes in {directory}\")\n",
    "    \n",
    "    # 3. create a dictionary of index labels \n",
    "    class_to_idx = {class_name: i for i, class_name in enumerate(classes)}\n",
    "    return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F_Banana': 0,\n",
       " 'F_Lemon': 1,\n",
       " 'F_Lulo': 2,\n",
       " 'F_Mango': 3,\n",
       " 'F_Orange': 4,\n",
       " 'F_Strawberry': 5,\n",
       " 'F_Tamarillo': 6,\n",
       " 'F_Tomato': 7,\n",
       " 'S_Banana': 8,\n",
       " 'S_Lemon': 9,\n",
       " 'S_Lulo': 10,\n",
       " 'S_Mango': 11,\n",
       " 'S_Orange': 12,\n",
       " 'S_Strawberry': 13,\n",
       " 'S_Tamarillo': 14,\n",
       " 'S_Tomato': 15}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes, class_to_idx = find_classes(directory=IMAGE_PATH)\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/spoiled-fresh/FRUIT-16K/F_Banana')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_PATH / classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. catch all the folder classes as iterables \n",
    "len(list(Path(IMAGE_PATH / classes[0]).glob(\"*.jpg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "a.extend([4, 5, 6])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a custom dataset class \n",
    "\n",
    "# 1. subclass torch.utils.data.Dataset \n",
    "class ImageFolderCustom(Dataset):\n",
    "    # 2. initialize the constructor\n",
    "    def __init__(self, targ_dir: str, heads: list[str], transform=None, is_training: bool = True):\n",
    "        # 3. create several attributes \n",
    "        # get all the image paths\n",
    "        self.training = []\n",
    "        self.testing = []\n",
    "        for tag in heads: \n",
    "            self.img_list = list(Path(targ_dir / tag).glob(\"*.jpg\"))\n",
    "            self.train_length = int(len(self.img_list) * 0.8)\n",
    "            self.training.extend(self.img_list[:self.train_length])\n",
    "            self.testing.extend(self.img_list[self.train_length:])\n",
    "\n",
    "        if is_training: \n",
    "            self.paths = self.training\n",
    "        else: \n",
    "            self.paths = self.testing\n",
    "        # setup transforms\n",
    "        self.transform = transform\n",
    "        # create classes and class_to_idx \n",
    "        self.classes, self.class_to_idx = find_classes(targ_dir)\n",
    "\n",
    "    # 4. create a function to load images \n",
    "    def load_image(self, index: int) -> Image.Image: \n",
    "        \"opens an image via a path and returns it\"\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path)\n",
    "    \n",
    "    # 5. overwrite __len__()\n",
    "    def __len__(self) -> int: \n",
    "        return len(self.paths)\n",
    "    \n",
    "    # 6. overwrite __getitem__() to return a particular sample\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"returns one sample of data, data and the label (X, y)\"\n",
    "        img = self.load_image(index)\n",
    "        class_name = self.paths[index].parent.name # expects path in format: data_folder/class_name/image.jpg\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "        # transform if necessary \n",
    "        if self.transform:\n",
    "            return self.transform(img), class_idx\n",
    "        else: \n",
    "            return img, class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)), \n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(), \n",
    "    normalize\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)), \n",
    "    transforms.ToTensor(), \n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out ImageFolderCustom()\n",
    "train_data_custom = ImageFolderCustom(targ_dir=IMAGE_PATH, heads=classes, \n",
    "                                        transform=train_transform, is_training=True)\n",
    "\n",
    "test_data_custom = ImageFolderCustom(targ_dir=IMAGE_PATH, heads=classes,\n",
    "                                        transform=test_transform, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pathlib.WindowsPath"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_setup import create_dataloaders\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader, test_dataloader, class_names = create_dataloaders(image_dir=IMAGE_PATH, heads=classes, train_transform=train_transform, test_transform=test_transform, batch_size=BATCH_SIZE, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,\n",
       " 100,\n",
       " ['F_Banana',\n",
       "  'F_Lemon',\n",
       "  'F_Lulo',\n",
       "  'F_Mango',\n",
       "  'F_Orange',\n",
       "  'F_Strawberry',\n",
       "  'F_Tamarillo',\n",
       "  'F_Tomato',\n",
       "  'S_Banana',\n",
       "  'S_Lemon',\n",
       "  'S_Lulo',\n",
       "  'S_Mango',\n",
       "  'S_Orange',\n",
       "  'S_Strawberry',\n",
       "  'S_Tamarillo',\n",
       "  'S_Tomato'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(test_dataloader), class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup hyperparameters\n",
    "models = [\"effnetb0\", \"effnetb2\"]\n",
    "num_epochs = [5]\n",
    "train_dataloaders = {\"fruitsvegs0\": train_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] experiment number: 1\n",
      "[INFO] model: effnetb0\n",
      "[INFO] dataloader: fruitsvegs0\n",
      "[INFO] number of epochs: 5\n",
      "[INFO] created a model effnetb0\n",
      "[INFO] Created SummaryWriter(), saving to: runs\\2024-08-23\\fruitsvegs0\\effnetb0\\5_epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.5014 | train_acc: 0.9327 | test_loss: 0.3278 | test_acc: 0.9109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:55<03:40, 55.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.1112 | train_acc: 0.9835 | test_loss: 0.2340 | test_acc: 0.9306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:52<02:49, 56.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.0721 | train_acc: 0.9866 | test_loss: 0.2082 | test_acc: 0.9303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:51<01:55, 57.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.0543 | train_acc: 0.9894 | test_loss: 0.1383 | test_acc: 0.9550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [03:49<00:57, 57.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.0456 | train_acc: 0.9912 | test_loss: 0.1576 | test_acc: 0.9450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:47<00:00, 57.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to: models\\07_effnetb0_fruitsvegs0_5_epochs.pt\n",
      "--------------------------------------------------\n",
      "\n",
      "[INFO] experiment number: 2\n",
      "[INFO] model: effnetb2\n",
      "[INFO] dataloader: fruitsvegs0\n",
      "[INFO] number of epochs: 5\n",
      "[INFO] created a model effnetb2\n",
      "[INFO] Created SummaryWriter(), saving to: runs\\2024-08-23\\fruitsvegs0\\effnetb2\\5_epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.5092 | train_acc: 0.9251 | test_loss: 0.2748 | test_acc: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:15<05:00, 75.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.1184 | train_acc: 0.9812 | test_loss: 0.2028 | test_acc: 0.9463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [02:35<03:55, 78.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.0800 | train_acc: 0.9845 | test_loss: 0.1591 | test_acc: 0.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [03:56<02:38, 79.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.0613 | train_acc: 0.9883 | test_loss: 0.1514 | test_acc: 0.9519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [05:18<01:20, 80.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.0499 | train_acc: 0.9894 | test_loss: 0.1541 | test_acc: 0.9513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:40<00:00, 80.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to: models\\07_effnetb2_fruitsvegs0_5_epochs.pt\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from experiments import run_experiment as rex \n",
    "\n",
    "rex(train_dataloaders=train_dataloaders, test_dataloader=test_dataloader, num_epochs=num_epochs, models=models, class_names=class_names, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
